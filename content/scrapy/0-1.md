---
title: "추천 학습 가이드"
slug: 0-1
category: "0. 추천 학습 가이드"
---

코사다마의 웹크롤링 심화 스터디에 참여하신 모든 분들을 환영합니다 🙌


### 스터디 목표

본 커리큘럼은 웹크롤링 심화 과정으로 기존 데이터 사이언스 입문에서 배웠던 BeautifulSoup나 Selenium보다 상당히 복잡한, **Scrapy**라는 새로운 크롤링 프레임워크를 다루려고 합니다.

Scrapy는 빠른 크롤링 속도와 넓은 확장성, 뛰어난 데이터 처리와 저장 능력을 가지고 있습니다. 이러한 장점 덕분에 이미 해외에서는 자주 쓰이고 있는 고급 기법이죠 ✨

Scrapy는 **터미널 환경**에서 크롤링이 이루어지기 때문에 처음 배우는 입장에서는 상당히 어려울 수 있습니다. 그래서 이번 커리큘럼에서는 Scrapy의 모든 부분을 다루기 보다는, **기본적인 사용법을 익히는 것을 목표**로 합니다. 


### 스터디 진행환경

Scrapy는 **터미널 환경**에서 작업합니다. 아래 영상은 본 커리큘럼을 이해하는 데 도움이 되니 시청 바랍니다.

<iframe class="w-full" style="aspect-ratio: 16 / 9;" src="https://www.youtube.com/embed/6z7FVYXnk3E" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


### 추천 학습 양
<table> 
<thead> 
<tr>  
<th>주차</th> 
<th>학습 대주제</th>  
<th>학습 소주제</th>  
</tr>  
</thead> 
<tbody>  
<tr> 
<td rowspan=3>1주차</td>  
<td>1. Scrapy 소개 및 설치</td> 
<td> 
1-1. Scrapy란?<br> 
1-2. Scrapy는 객체 지향 프로그래밍이다!<br>
1-3. Scrapy 설치하기<br>
</td> 
</tr> 
<tr> 
<td>2. Scrapy shell</td> 
<td> 
2-1. Scrapy shell이란?<br> 
2-2. Scrapy shell에서 CSS Selector와 XPath로 데이터 가져오기<br>
</td>
</tr>   
<td>3. Scrapy 프로젝트 생성</td> 
<td> 
3-1. Scrapy 프로젝트 생성<br> 
</td>     
<tr>  
<td rowspan=2>2주차</td> 
<td>4. Spider(크롤러) 만들기</td> 
<td> 
4-1. Spider(크롤러) 만들기<br>
4-2. Spider 클래스<br> 
4-2. Robots.txt(로봇 배제 표준)<br>
</td>
</tr>  
<tr>  
<td>5. 크롤링 데이터 다루기</td>
<td> 
5-1. Item 만들기<br> 
5-2. Spider 수정하기<br>
5-3. 데이터 저장하기<br>
5-4. 데이터 후처리하기<br>
</td>
</tr>  
<tr>  
<td rowspan=1>3주차</td> 
<td>6. [프로젝트] 11번가 사이트 카테고리별 베스트 상품 크롤링</td> 
<td> 
6-1. 프로젝트, Spider(크롤러) 만들기<br> 
6-2. Item 만들기 <br>
6-3. Request 메서드, callback과 meta 파라미터 <br>
6-4. 메인 카테고리의 베스트 상품 크롤링 <br> 
6-5. 메인 카테고리, 서브 카테고리의 베스트 상품 크롤링<br>
6-6. 데이터 후처리 및 저장
</td>
</tr>  
<tr>  
<td rowspan=2>4주차</td> 
<td>7. 텍스트 에디터 - VS Code</td> 
<td> 
7-1. VS Code 설치하기<br> 
7-2. VS Code 사용 팁⭐ <br>
7-3. VS Code에서 작업하기 <br>
</td>
</tr>  
<tr>  
<td>8. Scrapy Logging</td>
<td> 
8-1. Scrapy Log_LEVEL을 통한 오류 찾기 <br> 
8-2. Log를 파일로 저장하기 <br>
</td>
</tr>  
</tbody> 
</table>

### 추천 학습 과제
<table> 
<thead> 
<tr>  
<th>주차</th> 
<th>학습 과제</th>  
</tr>  
</thead> 
<tbody>  
<tr> 
<td>1주차</td>  
<td>11번가 CSS Selector 경로 추출</td> 
</tr> 
<tr> 
<td>2주차</td> 
<td>11번가 베스트 카테고리의 상품가격&상품명 크롤링</td>
</tr>   
<td>3주차</td> 
<td>11번가 메인 카테고리&서브 카테고리 베스트 상품 1~5위 크롤링&저장</td>     
<tr>  
<td>4주차</td> 
<td>G마켓 메인 카테고리&서브 카테고리 베스트 상품 1~5위 크롤링</td> 
</tr>  
</tbody> 
</table>

### 추천 및 참고자료
웹크롤링 심화 커리큘럼을 제작하면서 참고한 자료들과 해당 스터디와 병행하면 좋은 자료들입니다. 모두 구매하셔도 좋지만, 가장 추천드리는 도서는 **카토 코타의 '파이썬을 이용한 웹 크롤링과 스크레이핑(위키북스)'** 입니다.

- 잔재미코딩, **『현존 최강 크롤링 기술: Scrapy와 Selenium 정복』**, (온라인강의, ****인프런)
- 카토 코타, **『파이썬을 이용한 웹 크롤링과 스크레이핑』**, 위키북스(2018), 80-83, 131-133, 267-320
- 라이언 미첼, **『파이썬으로 웹 크롤러 만들기(2판)』**, 한빛미디어(2019), 95-114
