---
title: '프로젝트, Spider(크롤러) 만들기'
slug: 6-1
category: '6. [프로젝트] 11번가 사이트 카테고리별 베스트 상품 크롤링'
---

지금까지 11번가 사이트를 통해 Scrapy 사용법을 간단히 알아봤다면, 이번에는 11번가 사이트의 카테고리별 베스트 상품을 크롤링하고 저장하는 실습을 해보겠습니다 🛒

📢 **유의사항**
>
> 11번가의 '베스트' 페이지를 들어가면 나오는 주소는 아래의 '**기존 주소**'와 같습니다. 해당 주소로 저번 주에 공부했었죠? 하지만 이번 주에는 다른 메인 카테고리 주소와의 일관성, 편의성을 위해 '**사용할 주소**'로 바꿔 실습할 예정입니다.
>
> ![0](/scrapy/6-1/0.png)
> 
> '**사용할 주소**' 뒤의 No=0은 0번째 메인 카테고리인 '전체', No=2는 2번째 메인 카테고리인 '의류'에 해당하는 주소를 의미한다는 것만 이해해두시면 됩니다.
>
> - **기존 주소**: [https://www.11st.co.kr/browsing/BestSeller.tmall?method=getBestSellerMain](https://www.11st.co.kr/browsing/BestSeller.tmall?method=getBestSellerMain)
> - **사용할 주소**: [https://www.11st.co.kr/browsing/BestSeller.tmall?method=getBestSellerMain&cornerNo=0](https://www.11st.co.kr/browsing/BestSeller.tmall?method=getBestSellerMain&cornerNo=0) (No=각 메인 카테고리의 고유번호)


```powershell
#터미널
# cd 명령어를 이용하여 저번 주에 사용했던, scrapy.cfg가 있는 경로로 먼저 이동

scrapy genspider st11_best "https://www.11st.co.kr/browsing/BestSeller.tmall?method=getBestSellerMain&cornerNo=0"
# 여기서는 https://를 붙이는데, 그 이유는 Request를 배우며 다룰 예정
```

본격적으로 크롤링을 하기 전, 가장 먼저 [11번가 사이트의 **robots.txt**(로봇 배제 표준](https://www.11st.co.kr/robots.txt))을 확인해봐야 합니다. 이전(2주차)에 배웠듯이, 이 사이트는 크롤링을 막아놓았으니 우리는 특정 설정을 **settings.py**에서 변경해 주어야만 크롤링을 실행할 수 있기 때문입니다.

```python
#settings.py
# 기존 settings.py 수정하여 사용
# DOWNLOAD_DELAY = 1   << # 추가해서 주석처리
ROBOTSTXT_OBEY = False # robots.txt 무시
FEED_EXPORT_ENCODING = 'utf-8' # 코드 직접 추가. 인코딩 문제(한글문자 깨짐) 해결 코드
															 # 그래도 깨지면 'cp949'로 바꾸기
